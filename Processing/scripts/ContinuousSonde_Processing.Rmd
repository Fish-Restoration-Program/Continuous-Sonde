---
title: "FRP_ContinuousWQ_Processing"
author: "DMC"
date: "6/23/2023"
output: html_document
---

The goal of this file is to make all data processing of raw EXO2 exports happen in R rather than a multitude of Excel files.

This chunk makes a dataframe with all the potential column names for CDFW FRP sondes so that we can replace them with simple versions

```{r column naming}
df_VarNames <- data.frame(ExoVariable = c("Date..MM.DD.YYYY.", "Time..HH.mm.ss.", "Time..Fract..Sec.", "Site.Name", "Chlorophyll.RFU", "Chlorophyll.ug.L", "Cond.µS.cm", "Depth.m", "fDOM.QSU", "fDOM.RFU", "nLF.Cond.µS.cm", "ODO...sat", "ODO...CB", "ODO.mg.L", "Pressure.psi.a", "Sal.psu", "SpCond.µS.cm", "BGA.PC.RFU", "BGA.PC.ug.L", "TDS.mg.L", "Turbidity.FNU", "TSS.mg.L", "Wiper.Position.volt", "Temp..C", "Vertical.Position.m", "Battery.V", "Cable.Pwr.V"),
                          ExoVariable_v2 = c("Date (MM/DD/YYYY)", "Time (HH:mm:ss)", "Time (Fract. Sec)", "Site Name", "Chlorophyll RFU", "Chlorophyll ug/L", "Cond \xb5S/cm", "Depth m", "fDOM QSU", "fDOM RFU", "nLF Cond \xb5S/cm", "ODO % sat", "ODO % local", "ODO mg/L", "Pressure psi a", "Sal psu", "SpCond \xb5S/cm", "BGA PC RFU", "BGA PC ug/L", "TDS mg/L", "Turbidity FNU", "TSS mg/L", "Wiper Position volt", "Temp \xb0C", "Vertical Position m", "Battery V", "Cable Pwr V"), 
                          ExoVariable_v3 = c("Date..MM.DD.YYYY.", "Time..HH.mm.ss.", "Time..Fract..Sec.", "Site.Name", "Chlorophyll.RFU", "Chlorophyll.ug.L", "Cond.µS.cm", "Depth.m", "fDOM.QSU", "fDOM.RFU", "nLF.Cond.µS.cm", "ODO...sat", "ODO...CB", "ODO.mg.L", "Pressure.psi.a", "Sal.psu", "SpCond.µS.cm", "TAL.PC.RFU", "BGA.PC.ug.L", "TDS.mg.L", "Turbidity.FNU", "TSS.mg.L", "Wiper.Position.volt", "Temp..C", "Vertical.Position.m", "Battery.V", "Cable.Pwr.V"),
                          VarName = c("Date", "Time", "tFracSec", "Site", "ChlRFU","ChlugL","Cond", "Depthm", "fDOMQSU", "fDOMRFU", "nCond", "DOsat", "DOcb", "DOmgL", "PressurePSI", "SalPSU", "SPC", "PCRFU", "PCugL", "TDSmgL", "Turb", "TSSmgL", "WiperPos", "TempC", "VertPositionm", "Battery", "CablePwr"),
                          PortalName = c("Date","Time",NA,"Site","Chl",NA,NA,"Depth",NA,"fDOM",NA,"DOsat",NA,"DOconc",NA,NA,"SPC","PC",NA,NA,"Turb",NA,NA,"TempC",NA,"Battery",NA))#,
                          #keepTorF = c(T,T,F,T,T,F,T,F,T,F,T,F,T,F,F,T,T,F,T,F,T,T,F,T,F))

save(df_VarNames, file = "working/CDFW_VarNamesConversion.RData")
```

First we are going to import each file into 2 pieces. The first piece will include the sonde metadata and the second piece will contain the continuous data.

```{r import datasets}
rm(list = ls())
'%ni%' = Negate('%in%') # new function that serves as the opposite of %in% operator
###
# Now we will change the names of the columns using the conversion developed previously
load(here::here("working","CDFW_VarNamesConversion.RData"))

# Dictate each pathway for the different sites
path2_DECK_Pool <- here::here("raw","DECK", "Pool")
path2_DECK_Breach <- here::here("raw","DECK", "Breach")
path2_FLYW <- here::here("raw","FLYW")
path2_TULE_Breach <- here::here("raw","TULE","FRP_DWR","TULE_Breach")
path2_TULE_PondC <- here::here("raw","TULE","FRP_DWR","TULE_PondC")
path2_ARNO_Ext <- here::here("raw","ARNO","Exterior")
path2_ARNO_Int <- here::here("raw","ARNO","Interior")
path2_BRAD_Ext <- here::here("raw","BRAD","Exterior")
path2_BRAD_Int <- here::here("raw","BRAD","Interior")
path2_LOWE_EastInt <- here::here("raw","LOWE","EastInterior")
path2_WING <- here::here("raw","WING")
path2_WINT <- here::here("raw","WINT")

# Made a dataframe of the pathways
pathnames <- data.frame(SiteName = c("FLYW","DECK_Pool","DECK_Breach","TULE_Breach","TULE_PondC","ARNO_Exterior","ARNO_Interior","BRAD_Exterior","BRAD_Interior","LOWE_EastInt","WING","WINT"), 
                        pathname = c(path2_FLYW, path2_DECK_Pool, path2_DECK_Breach, path2_TULE_Breach, path2_TULE_PondC, path2_ARNO_Ext, path2_ARNO_Int, path2_BRAD_Ext, path2_BRAD_Int, path2_LOWE_EastInt, path2_WING, path2_WINT))


# For loop nested with multiple for loops to: 
# 1) Open file path and make a data frame with names of individual files
# 2) Import the metadata and store them in list_all_meta
# 3) Import the raw data and store them in list_all_raw
# 4) Pull out dates of first and last observations 
# Start a list for all metadata (Station, Sonde ID, Sensors, etc.)
list_all_meta <- list()
# Start a list to store all raw data
list_all_raw <- list()
for(x in 1:nrow(pathnames)){
  # make a data frame with the file names of the raw data sets
  fname <- data.frame(fname = list.files(here::here(pathnames$pathname[x])), dfname = NA)
  # the name of the dataset will be the same as the file name but without the appendage
  fname$dfname <- substr(fname$fname, 0, nchar(fname$fname)-4)
  # make a temporary list to store the initial import of metadata
  list_meta <- list()
  for(i in 1:nrow(fname)){
    # Not all files are made equally... Some are encoded as 'utf-16' and others in 'utf-8'. In order to import all of them, we need to use two for loops depending on which file type is encountered.
    # First, we will make a logical variable to force loop to continue even if it hits a file that can't be read in
    skip_to_next <- FALSE
    # use the wrapper tryCatch to force loop
    tryCatch({ # forces for loop to continue even when error is encountered
      list_meta[[i]] <- NA
    # read in the head (first 10 lines) of the file and skip the first 6 lines
    rawmeta <- data.frame(head(read.csv(here::here(pathnames$pathname[x],fname$fname[i]),skip = 6, fileEncoding = "utf-16")))
    # transpose the data (from wide to long)
    meta_1 <- data.frame(data.table::transpose(rawmeta))
    # remove first 3 rows and re-order the columns
    meta_2 <- meta_1[-c(1:3),c(2,1,3)]
    # rename the columns
    colnames(meta_2) <- c("ExoVariable","ExoValue","ToRemove")
    # move the site name over to the column with the other variables of interest
    meta_2$ExoValue[which(meta_2$ExoVariable == "Site Name")] <- meta_2$ToRemove[which(meta_2$ExoVariable == "Site Name")]
    # keep only the 2 columns of interest
    meta_3 <- meta_2[,c("ExoVariable","ExoValue")]
    # make a new variable with the SondeID (stored in the 'Battery V' field)
    meta_3[nrow(meta_3)+1,] <- c("Sonde",meta_3$ExoValue[which(meta_3$ExoVariable == "Battery V")])
    # store the metadata data frame as a list object
    list_meta[[i]] <- meta_3
    # remove temporary objects from memory
    rm(rawmeta,meta_1,meta_2,meta_3)
    }, # end of tryCatch wrapper
    # when an error is encountered, the loop will be forced to continue and the warning(s) will be shown at the end
    error = function(e){ skip_to_next <<- TRUE})
    if(skip_to_next) {next}
  }
  
  # rename list objects based on file names in the order they were processed
  names(list_meta) <- fname$dfname
  
  # need to run a new for loop to account for data frames that did not get entered due to the errors encountered in previous for loop
  for(i in 1:nrow(fname)){
    if(is.data.frame(list_meta[[i]]) == FALSE){ # FALSE indicates that the particular object in the list at position 'i' did not import successfully
      rawmeta <- data.frame(head(read.csv(here::here(pathnames$pathname[x],fname$fname[i]),skip = 6)))
      # transpose the data
      meta_1 <- data.frame(data.table::transpose(rawmeta))
      # remove first 3 rows and re-order the columns
      meta_2 <- meta_1[-c(1:3),c(2,1,3)]
      # rename the columns
      colnames(meta_2) <- c("ExoVariable","ExoValue","ToRemove")
      # move the site name over to the column with the other variables of interest
      meta_2$ExoValue[which(meta_2$ExoVariable == "Site Name")] <- meta_2$ToRemove[which(meta_2$ExoVariable == "Site Name")]
      # keep only the 2 columns of interest
      meta_3 <- meta_2[,c("ExoVariable","ExoValue")]
      # make a new variable with the SondeID (stored in the 'Battery V' field)
      meta_3[nrow(meta_3)+1,] <- c("Sonde",meta_3$ExoValue[which(meta_3$ExoVariable == "Battery V")])
      # store the metadata data frame as a list object
      list_meta[[i]] <- meta_3
      # remove temporary objects from memory
      rm(rawmeta,meta_1,meta_2,meta_3)
      }
  }
  list_all_meta[[x]] <- list_meta # store the list of metadata into the overarching list of all the metadata
  
  # We will now import the raw data
  list_rawdata <- list() # Make a temporary list to store the raw data
  # Again, we need to use two for loops since the encoding for the csv files differ
  for(i in 1:nrow(fname)){
    # make a logical variable to force loop to continue even if it hits a file that can't be read in
    skip_to_next <- FALSE
    # use the wrapper tryCatch to force loop when an error is encountered
    tryCatch({
      list_rawdata[[i]] <- NA
    # read in the  file and skip the first 9 lines
    rawdf <- data.frame(read.csv(here::here(pathnames$pathname[x],fname$fname[i]),skip = 9, fileEncoding = "utf-16", header = T))
    # use a for loop to change the column name based on the CDFW_VarNamesConversion
    for(j in 1:length(colnames(rawdf))){
      for(k in 1:nrow(df_VarNames)){
        if(colnames(rawdf)[j] == df_VarNames$ExoVariable[k] | colnames(rawdf)[j] == df_VarNames$ExoVariable_v2[k] | colnames(rawdf)[j] == df_VarNames$ExoVariable_v3[k]){
          colnames(rawdf)[j] = df_VarNames$VarName[k]
        }
      }
    }
    # store the data frame as a list object
    list_rawdata[[i]] <- rawdf
    # remove temporary objects from memory
    rm(rawdf)
    }, 
    # when an error is encountered, the loop will be forced to continue and the warning(s) will be shown at the end
    error = function(e){ skip_to_next <<- TRUE})
    if(skip_to_next) {next}
  }
  
  # rename list objects based on file names in the order they were processed
  names(list_rawdata) <- fname$dfname
  
  # need to run a new for loop to account for data frames that did not get entered due to the errors encountered in previous for loop
  for(i in 1:nrow(fname)){
    if(is.data.frame(list_rawdata[[i]]) == FALSE){ # FALSE indicates that the particular object in the list at position 'i' did not import successfully
    # read in the file and skip the first 8 lines
    rawdf <- data.frame(read.csv(here::here(pathnames$pathname[x],fname$fname[i]),skip = 8, header = F))
    colnames(rawdf) <- rawdf[1,]
    rawdf <- rawdf[-1,]
    # use a for loop to change the column name based on the CDFW_VarNamesConversion
    for(j in 1:length(colnames(rawdf))){
      for(k in 1:nrow(df_VarNames)){
        if(colnames(rawdf)[j] == df_VarNames$ExoVariable_v2[k] | colnames(rawdf)[j] == df_VarNames$ExoVariable_v2[k] | colnames(rawdf)[j] == df_VarNames$ExoVariable_v3[k]){
          colnames(rawdf)[j] = df_VarNames$VarName[k]
        }
      }
    }
    # store the data frame as a list object
    list_rawdata[[i]] <- rawdf
    # remove temporary objects from memory
    rm(rawdf)
    }
  }
  list_all_raw[[x]] <- list_rawdata # store the list of raw data into the overarching list of all the raw data
  
  for(i in 1:nrow(fname)){
    df_temp <- list_all_raw[[x]][[i]]
    firstObs <- as.POSIXct(strptime(paste(df_temp$Date[1],df_temp$Time[1],sep = " "), format = "%m/%d/%Y %H:%M:%S"), tz = "UTC")
    lastObs <- as.POSIXct(strptime(paste(df_temp$Date[nrow(df_temp)],df_temp$Time[nrow(df_temp)],sep = " "), format = "%m/%d/%Y %H:%M:%S"), tz = "UTC")
    timing <- data.frame(ExoVariable = c("firstObs","lastObs"), ExoValue = c(firstObs,lastObs))
    list_all_meta[[x]][[i]] <- rbind.data.frame(list_all_meta[[x]][[i]], data.frame(ExoVariable = c("firstObs","lastObs"), 
                                                                                    ExoValue = c(as.character(firstObs),as.character(lastObs))))
    rm(df_temp,firstObs,lastObs,timing)
  }
}
names(list_all_meta) <- pathnames$SiteName
names(list_all_raw) <- pathnames$SiteName

# Standardize the name of objects in the list of raw data so that they can match up easily with objects made in other scripts
# This also formats the datetimestamp object for each dataset to UTC
for(i in 1:length(list_all_raw)){
  for(j in 1:length(list_all_raw[[i]])){
    names(list_all_raw[[i]])[j] <- paste(list_all_meta[[i]][[j]]$ExoValue[which(list_all_meta[[i]][[j]]$ExoVariable == "Sonde")],
                                         substr(list_all_meta[[i]][[j]]$ExoValue[which(list_all_meta[[i]][[j]]$ExoVariable == "firstObs")],0,10),
                                         substr(list_all_meta[[i]][[j]]$ExoValue[which(list_all_meta[[i]][[j]]$ExoVariable == "lastObs")],0,10),
                                         sep = " ") # extracts Sonde ID, date of first observation, and date of last observation
      list_all_raw[[i]][[j]]$dts <- as.POSIXct(strptime(paste(list_all_raw[[i]][[j]]$Date,list_all_raw[[i]][[j]]$Time,sep = " "), format = "%m/%d/%Y %H:%M:%S"), tz = "UTC")
  }
}

save(list_all_raw, list_all_meta, file = "working/CDFW_DWR_Lists_Raw_Meta.RData")
```

Trim datasets based on Start/Stop times of each deployment recorded in the Exchange Worksheet (See 'SondeWorksheets.Rmd')

```{r Primary Trim}
rm(list = ls())

load(here::here("working", "CDFW_DWR_Lists_Raw_Meta.RData"))
load(here::here("working","CDFW_ExchangeTimes.RData"))

# create a new list of trimmed data frames
list_all_trim1 <- list_all_raw
list_all_excess <- list() # create a list of removed rows from each data frame to review after process
for(i in 1:length(list_all_trim1)){
  list_excess <- list() # temporary list
  for(j in 1:length(list_all_trim1[[i]])){
    rtd_sondeID <- strsplit(names(list_all_trim1[[i]])[j], split = " ", fixed = TRUE)[[1]][1] # variable for sondeID
    rtd_dateDeploy <- strsplit(names(list_all_trim1[[i]])[j], split = " ", fixed = TRUE)[[1]][2] # variable for Deployment date
    rtd_dateRecov <- strsplit(names(list_all_trim1[[i]])[j], split = " ", fixed = TRUE)[[1]][3] # variable for Recovery date
    for(k in 1:nrow(df_DeployTimes)){ # remove rows for observations recorded after departure time 
      if(rtd_sondeID == df_DeployTimes$deployed_sonde_id[k] & rtd_dateDeploy == as.character(df_DeployTimes$date2[k])){
        list_all_trim1[[i]][[j]] <- list_all_trim1[[i]][[j]][which(list_all_trim1[[i]][[j]]$dts > df_DeployTimes$departure_time[k]),]
      }
    }
    for(kz in 1:nrow(df_DeployTimes)){ # remove rows for observations recorded before arrival time
      if(rtd_sondeID == df_RecoveryTimes$recovered_sonde_id[kz] & rtd_dateDeploy == as.character(df_RecoveryTimes$date2[kz])){
        list_all_trim1[[i]][[j]] <- list_all_trim1[[i]][[j]][which(list_all_trim1[[i]][[j]]$dts < df_RecoveryTimes$arrival_time[kz]),]
      }
    }
    list_excess[[j]] <- suppressMessages(dplyr::anti_join(list_all_raw[[i]][[j]],list_all_trim1[[i]][[j]])) # suppressMessages prevents the console from being overtaken by anti_join messages
  }
  names(list_excess) <- names(list_all_trim1[[i]])
  list_all_excess[[i]] <- list_excess
  rm(list_excess, rtd_sondeID, rtd_dateDeploy, rtd_dateRecov)
}
names(list_all_excess) <- names(list_all_trim1)

save(list_all_trim1, file = here::here("working","RTD_Trim1.RData"))
```

Trim the edges of the dataset based on whether the sonde has observations indicating it was out of the water.

```{r Secondary Trim}
rm(list = ls())
'%ni%' = Negate('%in%')
load(here::here("working","RTD_Trim1.RData"))
###
# Let's trim rows at the beginning and end
# First, specify the values that obviously suggest that the sensor was in air
var2check <- c("fDOMRFU","SPC","Depthm")
air_spc <- 10
air_fdom <- -0.0001 # works if fdom is calibrated correctly
air_depth <- -0.0001 # works if sonde is deployed at a deep enough depth (DECK deployments cut it really close on very low tides)

# create a list to store the data frames
list_all_trim2 <- list_all_trim1
list_all_excess2 <- list()
for(i in 1:length(list_all_trim1)){
  list_excess <- list()
  for(j in 1:length(list_all_trim1[[i]])){
    # make a temporary data frame copy of the raw dataset and add a column named 'trim'
    To_trim <- cbind.data.frame(list_all_trim2[[i]][[j]],data.frame(trim = NA))
    # First, look at deployment start/end times
    # dictate how many rows to look at in the beginning of the file
    trim_head <- c(1:100)
    # dictate how many rows to look at in the end of the file
    trim_tail <- c(nrow(To_trim)-99):nrow(To_trim)
    for(k in 1:length(var2check)){
      if(var2check[k] %ni% colnames(To_trim)==TRUE){
        varNeeded <- var2check[k]
        To_trim <- cbind.data.frame(To_trim, data.frame(varNeeded = NA))
        colnames(To_trim)[ncol(To_trim)] <- varNeeded
      }
    }
    # Mark any rows in the upper 20 rows as TRUE if any of the sensor measurements violates the thresholds
    To_trim$trim[trim_head] <- ifelse(To_trim$fDOMRFU[trim_head] < air_fdom | To_trim$SPC[trim_head] < air_spc | To_trim$Depthm[trim_head] < air_depth,
                                      T,
                                      F)
    # Mark any rows in the final 20 rows as TRUE if any of the sensor measurements violates the thresholds
    To_trim$trim[trim_tail] <- ifelse(To_trim$fDOMRFU[trim_tail] < air_fdom | To_trim$SPC[trim_tail] < air_spc | To_trim$Depthm[trim_tail] < air_depth,
                                      T,
                                      F)
    # Mark middle rows as FALSE
    To_trim$trim[which(is.na(To_trim$trim)==T)] <- F
    # Keep rows marked as FALSE
    df_trimmed <- To_trim[which(To_trim$trim == F),]
    # Remove 'trim' column and store the data frame as a list object 
    list_all_trim2[[i]][[j]] <- df_trimmed[,-which(names(df_trimmed) %in% c("trim"))]
    list_excess[[j]] <- suppressMessages(dplyr::anti_join(list_all_trim1[[i]][[j]],list_all_trim2[[i]][[j]]))
    # remove temporary objects from memory
    rm(To_trim, trim_head, trim_tail, df_trimmed)
  }
  names(list_excess) <- names(list_all_trim1[[i]])
  list_all_excess2[[i]] <- list_excess
  rm(list_excess)
}
names(list_all_trim2) <- names(list_all_trim1) 
names(list_all_excess2) <- names(list_all_trim1) 

save(list_all_excess2, list_all_trim2, file = here::here("working","RTD_Trim2.RData"))
```

Now, we will bring in the sensor ratings and associate them with each dataset. Ratings were calculated in the 'ErrorCalculations.Rmd' script. On 231228, DMC added Error Ratings from DWR (see 'DWRtranscribed_ErrorRatings.Rmd') that were transcribed by KP from the Excel calculation sheets.
```{r Apply quality scores}
rm(list = ls())
'%ni%' = Negate('%in%')
load(here::here("working","RTD_Trim2.RData"))
load(here::here("working","SensorRatings230714.RData"))
load(here::here("working","DWRtranscribed_Ratings.RData"))
load(here::here("working","CDFW_VarNamesConversion.RData"))
rm(list_all_excess2)
colnames(list_all_trim2[[1]][[1]])
df_VarNames$VarName
list_ratings[[1]]$varX
df_xNames <- data.frame(VarName = c("TempC","DOmgL","SPC","ChlRFU","PCRFU","fDOMRFU","Turb","pH"),
                        ErrorName = c("temp","DO", "sc","chl","pc","fdom","turb","pH"),
                        qcName = c("TempC_qcE","DOmgL_qcE","SPC_qcE","ChlRFU_qcE","PCRFU_qcE","fDOMRFU_qcE","Turb_qcE","pH_qcE"))

allRatings.CDFWold <- allRatings
allRatings <- rbind.data.frame(allRatings[,c("varX","sondeID","dateRecov","Rating_final")],
                               DWR_Ratings)

# create a new list of trimmed data frames
list_all_qc <- list_all_trim2
allRatings$nObs <- NA
#list_all_excess <- list() # create a list of removed rows from each data frame to review after process
for(i in 1:length(list_all_qc)){
  list_qc <- list() # temporary list
  for(j in 1:length(list_all_qc[[i]])){
    rtd_sondeID <- strsplit(names(list_all_qc[[i]])[j], split = " ", fixed = TRUE)[[1]][1] # variable for sondeID
    rtd_dateDeploy <- strsplit(names(list_all_qc[[i]])[j], split = " ", fixed = TRUE)[[1]][2] # variable for Deployment date
    rtd_dateRecov <- strsplit(names(list_all_qc[[i]])[j], split = " ", fixed = TRUE)[[1]][3] # variable for Recovery date
    df_temp <- cbind.data.frame(list_all_qc[[i]][[j]],
                                data.frame(TempC_qcE = NA,
                                           DOmgL_qcE = NA,
                                           SPC_qcE = NA,
                                           ChlRFU_qcE = NA,
                                           PCRFU_qcE = NA,
                                           fDOMRFU_qcE = NA,
                                           Turb_qcE = NA))
    # fill in rating columns of deployment dataframe with the Final Rating
    for(a in 1:ncol(df_temp)){
      for(b in 1:nrow(df_xNames)){
        if(colnames(df_temp)[a] == df_xNames$VarName[b]){
          df_temp[,df_xNames$qcName[b]] = allRatings$Rating_final[which(allRatings$varX == df_xNames$ErrorName[b] 
                                                                       & allRatings$sondeID == rtd_sondeID 
                                                                       & allRatings$dateRecov == rtd_dateRecov)]
        }
        # copy in number of rows (observations) for each deployment to determine % coverage of quality data
        allRatings$nObs[which(allRatings$sondeID == rtd_sondeID & allRatings$dateRecov == rtd_dateRecov)] <- nrow(df_temp)
      }
    }
    list_qc[[j]] <- df_temp
  }
  names(list_qc) <- names(list_all_trim2[[i]])
  list_all_qc[[i]] <- list_qc
  rm(list_qc, rtd_sondeID, rtd_dateDeploy, rtd_dateRecov)
}
names(list_all_qc) <- names(list_all_trim2)

library(plyr)
summ_2022 <- ddply(allRatings[-which(allRatings$varX %in% c("DO_sat","sc_InAir")),], c("varX","Rating_final"), summarise,
                   v = sum(nObs, na.rm = TRUE))
tot_2022 <- ddply(allRatings[which(is.na(allRatings$nObs)==F),], c("sondeID","dateRecov"), summarise,
                   v = sum(nObs, na.rm = TRUE),
                   t = mean(nObs, na.rm = TRUE))
allObs <- sum(tot_2022$t)

summ_2022$propX <- summ_2022$v/allObs
summ_2022$Rating_finalF <- factor(summ_2022$Rating_final, levels = c("Excellent","Good","Fair","Poor","MaxLimit","NA"))
summ_2022$varX_F <- factor(summ_2022$varX, levels = c("temp","sc","DO","turb","chl","pc","fdom","pH"))

library(ggplot2)
plo_summ <- ggplot(summ_2022, aes(varX_F, propX)) + geom_bar(aes(fill = Rating_finalF), stat = "identity")
plo_summ

save(list_all_qc, file = here::here("working","QCd_Data_FRP.RData"))
```

```{r Subset all 2022 data}
rm(list = ls())
load(here::here("working","QCd_Data_FRP.RData"))

# create a new list of qc'd data frames to be filtered by year
list_all_2022 <- list_all_qc

for(i in 1:length(list_all_qc)){
  #list_2022 <- list() # temporary list
  for(j in 1:length(list_all_qc[[i]])){
    rtd_sondeID <- strsplit(names(list_all_qc[[i]])[j], split = " ", fixed = TRUE)[[1]][1] # variable for sondeID
    rtd_dateDeploy <- as.numeric(substr(strsplit(names(list_all_qc[[i]])[j], split = " ", fixed = TRUE)[[1]][2],0,4)) # variable for Deployment date
    rtd_dateRecov <- as.numeric(substr(strsplit(names(list_all_qc[[i]])[j], split = " ", fixed = TRUE)[[1]][3],0,4)) # variable for Recovery date                              0)
    if((rtd_dateDeploy <= 2021 & rtd_dateRecov <= 2021) | (rtd_dateDeploy >= 2023 & rtd_dateRecov >= 2023)){
      list_all_2022[[i]][[j]] <- list(NULL)
    }
    rm(rtd_sondeID, rtd_dateDeploy, rtd_dateRecov)
  }
}

save(list_all_2022, file = here::here("working","QCd_2022.RData"))
FLYW <- do.call(rbind.data.frame, list_all_2022[[1]])
DECK <- do.call(rbind.data.frame, list_all_2022[[2]])
```

Call in list_all_2022 into the scripts "WaterVAR_QC.Rmd" (where VAR is the variable of interest) to perform further quality control measures.
